{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment-2\n",
    "\n",
    "1. Implement Backpropagation algorithm to train an ANN of configuration __2x2x1__ to achieve __XOR__ function."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer__: Neural network is defined and while training backpropagation algorithm is used for adjusting the weights so that the weights are adjusted making the neural network best fit to data as possible.\n",
    "\n",
    "The XOR truth table looks like:\n",
    "\n",
    "| Input      | Output |\n",
    "| ---------- | ------ |\n",
    "| 0    ,   0 |   0    |\n",
    "| 1    ,   0 |   1    |\n",
    "| 0    ,   1 |   1    |\n",
    "| 1    ,   1 |   0    |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid( net_output ):\n",
    "        output = 1 / ( 1 + np.exp(-net_output))\n",
    "        return output\n",
    "    \n",
    "class Layer:\n",
    "    def __init__(self, neurons, no_of_wghts, layer_no):\n",
    "        print(f\"Layer {layer_no+1} has {neurons} neurons and each neuron has {no_of_wghts} weights connected to it.\")\n",
    "        self.wght = np.random.normal(size=(neurons, no_of_wghts+1))\n",
    "        self.layer_no = layer_no+1\n",
    "        self.grad = np.empty(shape=(neurons, no_of_wghts+1))\n",
    "        self.delta = np.empty(shape=(1, neurons))\n",
    "    def activate_h(self, input):\n",
    "        #adding a single row for bias \n",
    "        _, col = input.shape\n",
    "        if self.wght.shape[1] == col:\n",
    "            self.activation = np.dot(input, self.wght.T)\n",
    "            self.n_output = sigmoid(self.activation)\n",
    "            self.n_output = np.c_[self.n_output, np.ones(shape=(self.n_output.shape[0], 1))]\n",
    "            return self.n_output\n",
    "        else:\n",
    "            raise Exception(f\"input {input.shape} and weights {self.wght.shape} shape not valid \")\n",
    "        \n",
    "    def activate_o(self, input):\n",
    "        #adding a single row for bias \n",
    "        _, col = input.shape\n",
    "        if self.wght.shape[1] == col:\n",
    "            self.activation = np.dot(input,self.wght.T )\n",
    "            self.n_output = sigmoid(self.activation)\n",
    "            return self.n_output\n",
    "        else:\n",
    "            raise Exception(f\"input {input.shape} and weights {self.wght.shape} shape not valid \")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Input(Layer):\n",
    "    def __init__(self, neurons, layer_no):\n",
    "        print(f\"Input Layer has {neurons} inputs.\")\n",
    "        self.neurons = neurons\n",
    "        self.layer_no = layer_no+1\n",
    "    def activate_h(self, input):\n",
    "        self.n_output = input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Network:\n",
    "    def __init__(self, *args) -> None:\n",
    "        self.layers = []\n",
    "        self.total_layers = len(args)\n",
    "        self.layers.append(Input(args[0],0))\n",
    "        for l in range(1, self.total_layers):\n",
    "            self.layers.append(Layer(args[l], args[l-1], l))\n",
    "    def forward(self, input):\n",
    "        self.input = input\n",
    "        input = np.c_[input, np.ones(shape=(input.shape[0],1))]\n",
    "        self.layers[0].activate_h(input)\n",
    "        for layer_no in range(1, self.total_layers-1):\n",
    "            input = self.layers[layer_no].activate_h(input)\n",
    "        self.output = self.layers[-1].activate_o(input)\n",
    "        \n",
    "        \n",
    "    def backward(self, target, learning_rate=10):\n",
    "        diff = target - self.output\n",
    "        derivative = self.output * ( 1 - self.output)\n",
    "        delta = diff * derivative\n",
    "        #output layer weight update\n",
    "        for d in range(len(self.output)):\n",
    "            diff = target[d] - self.output[d]\n",
    "            derivative = self.output[d] * (1 - self.output[d])\n",
    "            delta = diff * derivative\n",
    "            grad  = np.dot(delta.T[:,np.newaxis], self.layers[-2].n_output[d][np.newaxis,:])\n",
    "            self.layers[-1].grad = grad\n",
    "            self.layers[-1].delta = delta\n",
    "            #finding the gradients for weight update\n",
    "            for l in range(self.total_layers-1, 1, -1):\n",
    "                delta_h = np.dot(self.layers[l].delta, self.layers[l].wght[:, :-1]) # don't need the bias for the previous layers' weight update\n",
    "                deriv_h = (self.layers[l-1].n_output[d] * ( 1- self.layers[l-1].n_output[d]))[np.newaxis, :-1]\n",
    "                delta_h = delta_h * deriv_h\n",
    "                grad_h = np.dot(delta_h.T, self.layers[l-2].n_output[d][np.newaxis, :]) \n",
    "                self.layers[l-1].grad = grad_h\n",
    "                self.layers[l-1].delta = delta_h\n",
    "            #weight update\n",
    "            for layer in  range(1, self.total_layers):\n",
    "                self.layers[layer].wght = self.layers[layer].wght + (learning_rate * self.layers[layer].grad)\n",
    "            self.forward(self.input)     \n",
    "            \n",
    "    def train(self, input, output, learning_rate=1, epochs=1000):\n",
    "        for e in range(1, epochs+1):\n",
    "            self.forward(input)\n",
    "            self.backward(output, learning_rate=learning_rate)             \n",
    "            print(f\"{e} epochs completed.\", end=\"\\r\")\n",
    "        print(\"\",end='\\n')\n",
    "    \n",
    "    def test(self, input):\n",
    "        self.forward(input)\n",
    "        print(self.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Layer has 2 inputs.\n",
      "Layer 2 has 2 neurons and each neuron has 2 weights connected to it.\n",
      "Layer 3 has 1 neurons and each neuron has 2 weights connected to it.\n",
      "1000 epochs completed.\n",
      "[[0.95257338]\n",
      " [0.94988354]\n",
      " [0.0559636 ]\n",
      " [0.0502493 ]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "net = Network(2, 2, 1)\n",
    "\n",
    "# test = Layer(2, 2, 1)\n",
    "input = np.array([[1, 0],\n",
    "                  [0, 1],\n",
    "                  [0, 0],\n",
    "                  [1, 1]])\n",
    "output = np.array([ [1],\n",
    "                    [1],\n",
    "                    [0],\n",
    "                    [0] ])\n",
    "net.train(input, output)\n",
    "net.test(input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Layer has 3 inputs.\n",
      "Layer 2 has 2 neurons and each neuron has 3 weights connected to it.\n",
      "Layer 3 has 2 neurons and each neuron has 2 weights connected to it.\n",
      "Layer 4 has 1 neurons and each neuron has 2 weights connected to it.\n",
      "1000 epochs completed.\n",
      "[[0.00968035]\n",
      " [0.02182572]\n",
      " [0.02065927]\n",
      " [0.97589547]\n",
      " [0.02059313]\n",
      " [0.97590901]\n",
      " [0.97536999]\n",
      " [0.98375435]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "net = Network(3, 2, 2, 1)\n",
    "arr = np.arange(0, 8)\n",
    "max_len = len(np.binary_repr(arr[-1]))\n",
    "input = np.array([list(np.binary_repr(x).zfill(max_len)) for x in arr], dtype=int)\n",
    "output = np.array([[0],\n",
    "                   [0],\n",
    "                   [0],\n",
    "                   [1],\n",
    "                   [0],\n",
    "                   [1],\n",
    "                   [1],\n",
    "                   [1]])\n",
    "net.train(input, output)\n",
    "net.test(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
